name: Run ADF Pipeline - NEW

on:
  workflow_dispatch:

jobs:
  run-adf:
    runs-on: ubuntu-latest

    steps:
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Trigger ADF Pipeline
        id: trigger_pipeline
        run: |
          run_id=$(az datafactory pipeline create-run \
            --factory-name ${{ secrets.ADF_NAME }} \
            --resource-group ${{ secrets.ADF_RESOURCE_GROUP }} \
            --name "pipeline1" \
            --query runId -o tsv)
          echo "run_id=$run_id"
          echo "run_id=$run_id" >> $GITHUB_OUTPUT

      - name: Wait for pipeline to complete
        id: wait_pipeline
        run: |
          run_id=${{ steps.trigger_pipeline.outputs.run_id }}
          status="InProgress"
          while [[ "$status" == "InProgress" || "$status" == "Queued" ]]; do
            echo "Pipeline run status: $status"
            sleep 15
            status=$(az datafactory pipeline-run show \
              --factory-name ${{ secrets.ADF_NAME }} \
              --resource-group ${{ secrets.ADF_RESOURCE_GROUP }} \
              --run-id $run_id \
              --query status -o tsv)
          done

          echo "Final pipeline run status: $status"
          if [[ "$status" != "Succeeded" ]]; then
            echo "Pipeline failed!"
            exit 1
          fi

          echo "run_id=$run_id" >> $GITHUB_OUTPUT

      - name: Get Databricks notebook output from ADF pipeline run
        id: get_notebook_output
        run: |
          run_id=${{ steps.wait_pipeline.outputs.run_id }}

          pipeline_info=$(az datafactory pipeline-run show \
            --factory-name ${{ secrets.ADF_NAME }} \
            --resource-group ${{ secrets.ADF_RESOURCE_GROUP }} \
            --run-id $run_id \
            --output json)

          start_time=$(echo "$pipeline_info" | jq -r '.runStart')
          end_time=$(echo "$pipeline_info" | jq -r '.runEnd')

          activity_output=$(az datafactory activity-run query-by-pipeline-run \
            --factory-name ${{ secrets.ADF_NAME }} \
            --resource-group ${{ secrets.ADF_RESOURCE_GROUP }} \
            --run-id $run_id \
            --last-updated-after "$start_time" \
            --last-updated-before "$end_time" \
            --output json)

          notebook_output=$(echo "$activity_output" | jq -r '.value[] | select(.activityName == "RunDatabricksNotebook") | .output.runOutput')

          echo "Raw notebook output string:"
          echo "$notebook_output"

          echo "notebook_output=$notebook_output" >> $GITHUB_OUTPUT

      - name: Print parsed notebook output JSON
        run: |
          echo '${{ steps.get_notebook_output.outputs.notebook_output }}' | jq .

      - name: Download Deequ Log from Data Lake
        run: |
          echo "üîç Fetching latest Deequ log file from Data Lake..."
          
          # List log blobs sorted by last modified
          latest_blob=$(az storage blob list \
            --account-name ${{ secrets.STORAGE_ACCOUNT }} \
            --container-name raw \
            --prefix logs/data_quality_log_ \
            --query "sort_by([].{name:name, lastModified:properties.lastModified}, &lastModified)[-1].name" \
            --output tsv)

          echo "üìÇ Latest blob: $latest_blob"

          az storage blob download \
            --account-name ${{ secrets.STORAGE_ACCOUNT }} \
            --container-name raw \
            --name "$latest_blob" \
            --file log.json \
            --auth-mode login

      - name: Print Deequ Log Contents
        run: |
          echo "üìã Deequ Log Contents:"
          cat log.json | jq .
