name: Run ADF Pipeline - NEW

on:
  workflow_dispatch:

jobs:
  run-adf:
    runs-on: ubuntu-latest

    steps:
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Trigger ADF Pipeline
        id: trigger_pipeline
        run: |
          run_id=$(az datafactory pipeline create-run \
            --factory-name ${{ secrets.ADF_NAME }} \
            --resource-group ${{ secrets.ADF_RESOURCE_GROUP }} \
            --name "pipeline1" \
            --query runId -o tsv)
          echo "run_id=$run_id"
          echo "run_id=$run_id" >> $GITHUB_OUTPUT

      - name: Wait for pipeline to complete
        id: wait_pipeline
        run: |
          run_id=${{ steps.trigger_pipeline.outputs.run_id }}
          status="InProgress"
          while [[ "$status" == "InProgress" || "$status" == "Queued" ]]; do
            echo "Pipeline run status: $status"
            sleep 15
            status=$(az datafactory pipeline-run show \
              --factory-name ${{ secrets.ADF_NAME }} \
              --resource-group ${{ secrets.ADF_RESOURCE_GROUP }} \
              --run-id $run_id \
              --query status -o tsv)
          done

          echo "Final pipeline run status: $status"
          if [[ "$status" != "Succeeded" ]]; then
            echo "Pipeline failed!"
            exit 1
          fi

          echo "run_id=$run_id" >> $GITHUB_OUTPUT

      - name: Get Databricks notebook output from ADF pipeline run
        id: get_notebook_output
        run: |
          run_id=${{ steps.wait_pipeline.outputs.run_id }}

          # Get pipeline run start and end times
          pipeline_info=$(az datafactory pipeline-run show \
            --factory-name ${{ secrets.ADF_NAME }} \
            --resource-group ${{ secrets.ADF_RESOURCE_GROUP }} \
            --run-id $run_id \
            --output json)

          start_time=$(echo "$pipeline_info" | jq -r '.runStart')
          end_time=$(echo "$pipeline_info" | jq -r '.runEnd')

          # Query activity run output within that time range
          activity_output=$(az datafactory activity-run query-by-pipeline-run \
            --factory-name ${{ secrets.ADF_NAME }} \
            --resource-group ${{ secrets.ADF_RESOURCE_GROUP }} \
            --run-id $run_id \
            --last-updated-after "$start_time" \
            --last-updated-before "$end_time" \
            --output json)

          # Extract notebook output from Databricks activity
          notebook_output=$(echo "$activity_output" | jq -r '.value[] | select(.activityName == "RunDatabricksNotebook") | .output.runOutput')

          echo "Raw notebook output string:"
          echo "$notebook_output"

          # Save the output for next steps
          echo "notebook_output=$notebook_output" >> $GITHUB_OUTPUT

      - name: Print parsed notebook output JSON
        run: |
          # notebook_output is a JSON string â€” parse and pretty print it
          echo '${{ steps.get_notebook_output.outputs.notebook_output }}' | jq .
